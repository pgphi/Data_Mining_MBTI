{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76455dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>encodedType</th>\n",
       "      <th>preprocessed_posts</th>\n",
       "      <th>extro_intro</th>\n",
       "      <th>intu_obs</th>\n",
       "      <th>feel_think</th>\n",
       "      <th>prosp_judg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>8</td>\n",
       "      <td>['youtube', 'tumblr', 'enfp', 'intj', 'moment'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>['im', 'finding', 'the', 'lack', 'of', 'post',...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>11</td>\n",
       "      <td>['good', 'one', 'youtube', 'of', 'course', 'i'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>10</td>\n",
       "      <td>['dear', 'intp', 'i', 'enjoyed', 'conversation...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>2</td>\n",
       "      <td>['youre', 'fired', 'thats', 'another', 'silly'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  encodedType  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...            8   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...            3   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           11   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           10   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...            2   \n",
       "\n",
       "                                  preprocessed_posts  extro_intro  intu_obs  \\\n",
       "0  ['youtube', 'tumblr', 'enfp', 'intj', 'moment'...            0         1   \n",
       "1  ['im', 'finding', 'the', 'lack', 'of', 'post',...            1         1   \n",
       "2  ['good', 'one', 'youtube', 'of', 'course', 'i'...            0         1   \n",
       "3  ['dear', 'intp', 'i', 'enjoyed', 'conversation...            0         1   \n",
       "4  ['youre', 'fired', 'thats', 'another', 'silly'...            1         1   \n",
       "\n",
       "   feel_think  prosp_judg  \n",
       "0           1           0  \n",
       "1           0           1  \n",
       "2           0           1  \n",
       "3           0           0  \n",
       "4           0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"mbti_preprocessed_complete.csv\", index_col=0)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677b98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_train_test_split(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42069)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b1cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer created 620 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actual</th>\n",
       "      <th>add</th>\n",
       "      <th>admit</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xd</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175949</td>\n",
       "      <td>0.152955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151928</td>\n",
       "      <td>0.088888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074559</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.071837</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  absolutely  accept  accurate    across  act    action  \\\n",
       "0     0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1     0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.175949    0.152955     0.0  0.092026  0.000000  0.0  0.000000   \n",
       "3     0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.151928   \n",
       "4     0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "...        ...         ...     ...       ...       ...  ...       ...   \n",
       "8670  0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "8671  0.000000    0.000000     0.0  0.000000  0.134748  0.0  0.000000   \n",
       "8672  0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "8673  0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "8674  0.000000    0.000000     0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "        actual  add     admit  ...   writing   written  wrote        xd  \\\n",
       "0     0.000000  0.0  0.000000  ...  0.000000  0.000000    0.0  0.000000   \n",
       "1     0.000000  0.0  0.080565  ...  0.000000  0.000000    0.0  0.000000   \n",
       "2     0.000000  0.0  0.000000  ...  0.075340  0.000000    0.0  0.000000   \n",
       "3     0.088888  0.0  0.000000  ...  0.000000  0.000000    0.0  0.000000   \n",
       "4     0.000000  0.0  0.000000  ...  0.000000  0.095449    0.0  0.092035   \n",
       "...        ...  ...       ...  ...       ...       ...    ...       ...   \n",
       "8670  0.000000  0.0  0.081479  ...  0.000000  0.000000    0.0  0.078123   \n",
       "8671  0.000000  0.0  0.000000  ...  0.287795  0.000000    0.0  0.000000   \n",
       "8672  0.000000  0.0  0.000000  ...  0.000000  0.000000    0.0  0.000000   \n",
       "8673  0.069657  0.0  0.000000  ...  0.053322  0.000000    0.0  0.000000   \n",
       "8674  0.000000  0.0  0.000000  ...  0.000000  0.000000    0.0  0.075843   \n",
       "\n",
       "      yesterday  youd     youll    young   younger     youve  \n",
       "0           0.0   0.0  0.000000  0.00000  0.000000  0.096755  \n",
       "1           0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "2           0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "3           0.0   0.0  0.074559  0.00000  0.000000  0.132613  \n",
       "4           0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "...         ...   ...       ...      ...       ...       ...  \n",
       "8670        0.0   0.0  0.068736  0.00000  0.071837  0.000000  \n",
       "8671        0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "8672        0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "8673        0.0   0.0  0.000000  0.00000  0.000000  0.000000  \n",
       "8674        0.0   0.0  0.000000  0.06933  0.000000  0.000000  \n",
       "\n",
       "[8675 rows x 620 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "Y = df.iloc[:, 2].values #EncodedType\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.3)\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "print(\"Vectorizer created {} features.\".format(len(vectorizer.get_feature_names_out())))\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "display(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a446ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.35      0.31      0.33        55\n",
      "        ENFP       0.51      0.45      0.48       212\n",
      "        ENTJ       0.53      0.42      0.47        74\n",
      "        ENTP       0.53      0.54      0.54       196\n",
      "        ESFJ       0.44      0.36      0.40        11\n",
      "        ESFP       0.00      0.00      0.00        14\n",
      "        ESTJ       0.33      0.18      0.24        11\n",
      "        ESTP       0.57      0.29      0.38        28\n",
      "        INFJ       0.55      0.58      0.57       436\n",
      "        INFP       0.54      0.66      0.59       545\n",
      "        INTJ       0.60      0.48      0.53       365\n",
      "        INTP       0.55      0.63      0.59       378\n",
      "        ISFJ       0.62      0.41      0.49        58\n",
      "        ISFP       0.44      0.33      0.38        73\n",
      "        ISTJ       0.54      0.31      0.40        61\n",
      "        ISTP       0.54      0.52      0.53        86\n",
      "\n",
      "    accuracy                           0.54      2603\n",
      "   macro avg       0.48      0.41      0.43      2603\n",
      "weighted avg       0.54      0.54      0.53      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "predicted = estimator.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "types = df.iloc[:, 0].values\n",
    "types = sorted(list(set(types)))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c0dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Introverted       0.85      0.93      0.89      2002\n",
      " Extroverted       0.66      0.47      0.55       601\n",
      "\n",
      "    accuracy                           0.82      2603\n",
      "   macro avg       0.76      0.70      0.72      2603\n",
      "weighted avg       0.81      0.82      0.81      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Introverted-Extroverted\n",
    "\n",
    "# Get data from dataset\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "Y = df.iloc[:, 4].values #EncodedType\n",
    "\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.3)\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Create splits\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.svm import LinearSVC\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "predicted = estimator.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "types = ['Introverted', 'Extroverted']\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3129979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Sensing       0.61      0.31      0.41       342\n",
      "   Intuition       0.90      0.97      0.94      2261\n",
      "\n",
      "    accuracy                           0.88      2603\n",
      "   macro avg       0.76      0.64      0.67      2603\n",
      "weighted avg       0.86      0.88      0.87      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Sensing-Intuition\n",
    "\n",
    "# Get data from dataset\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "Y = df.iloc[:, 5].values #EncodedType\n",
    "\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.3)\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Create splits\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.svm import LinearSVC\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "predicted = estimator.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "types = ['Sensing', 'Intuition']\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9ee5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Thinking       0.79      0.76      0.77      1199\n",
      "     Feeling       0.80      0.83      0.81      1404\n",
      "\n",
      "    accuracy                           0.80      2603\n",
      "   macro avg       0.80      0.79      0.79      2603\n",
      "weighted avg       0.80      0.80      0.80      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Thinking-Feeling\n",
    "\n",
    "# Get data from dataset\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "Y = df.iloc[:, 6].values #EncodedType\n",
    "\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.3)\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Create splits\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.svm import LinearSVC\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "predicted = estimator.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "types = ['Thinking', 'Feeling']\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e0e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Judging       0.71      0.58      0.63      1071\n",
      "  Perceiving       0.74      0.83      0.78      1532\n",
      "\n",
      "    accuracy                           0.73      2603\n",
      "   macro avg       0.72      0.70      0.71      2603\n",
      "weighted avg       0.72      0.73      0.72      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Judging-Perceiving\n",
    "\n",
    "# Get data from dataset\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "Y = df.iloc[:, 7].values #EncodedType\n",
    "\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.3)\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Create splits\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.svm import LinearSVC\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "predicted = estimator.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "types = ['Judging', 'Perceiving']\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbb876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
