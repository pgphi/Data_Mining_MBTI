{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b53f7c1",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd081eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f09c37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>encodedType</th>\n",
       "      <th>preprocessed_posts</th>\n",
       "      <th>extro_intro</th>\n",
       "      <th>intu_obs</th>\n",
       "      <th>feel_think</th>\n",
       "      <th>prosp_judg</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>avg_exclam_count</th>\n",
       "      <th>avg_fullstop_count</th>\n",
       "      <th>avg_emoji_count</th>\n",
       "      <th>avg_count_of_hello</th>\n",
       "      <th>avg_count_of_hi</th>\n",
       "      <th>avg_count_of_extroverted_bigrams</th>\n",
       "      <th>avg_count_of_extroverted_stylistic_impressions</th>\n",
       "      <th>avg_count_of_interoverted_quantifiers</th>\n",
       "      <th>avg_count_of_introverted_first_person_singular_pronoun</th>\n",
       "      <th>avg_count_of_introverted_negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>8</td>\n",
       "      <td>['youtube', 'tumblr', 'enfp', 'intj', 'moment'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>['im', 'finding', 'the', 'lack', 'of', 'post',...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>11</td>\n",
       "      <td>['good', 'one', 'youtube', 'of', 'course', 'i'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>10</td>\n",
       "      <td>['dear', 'intp', 'i', 'enjoyed', 'conversation...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>2</td>\n",
       "      <td>['youre', 'fired', 'thats', 'another', 'silly'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  encodedType  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...            8   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...            3   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           11   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           10   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...            2   \n",
       "\n",
       "                                  preprocessed_posts  extro_intro  intu_obs  \\\n",
       "0  ['youtube', 'tumblr', 'enfp', 'intj', 'moment'...            0         1   \n",
       "1  ['im', 'finding', 'the', 'lack', 'of', 'post',...            1         1   \n",
       "2  ['good', 'one', 'youtube', 'of', 'course', 'i'...            0         1   \n",
       "3  ['dear', 'intp', 'i', 'enjoyed', 'conversation...            0         1   \n",
       "4  ['youre', 'fired', 'thats', 'another', 'silly'...            1         1   \n",
       "\n",
       "   feel_think  prosp_judg  avg_word_count  avg_exclam_count  \\\n",
       "0           1           0           12.10               0.0   \n",
       "1           0           1           24.38               0.0   \n",
       "2           0           1           17.70               0.0   \n",
       "3           0           0           22.26               0.0   \n",
       "4           0           0           20.32               0.0   \n",
       "\n",
       "   avg_fullstop_count  avg_emoji_count  avg_count_of_hello  avg_count_of_hi  \\\n",
       "0                0.16             0.08                 0.0              0.0   \n",
       "1                0.04             0.08                 0.0              0.0   \n",
       "2                0.08             0.00                 0.0              0.0   \n",
       "3                0.14             0.02                 0.0              0.0   \n",
       "4                0.08             0.06                 0.0              0.0   \n",
       "\n",
       "   avg_count_of_extroverted_bigrams  \\\n",
       "0                              0.14   \n",
       "1                              0.28   \n",
       "2                              0.26   \n",
       "3                              0.20   \n",
       "4                              0.14   \n",
       "\n",
       "   avg_count_of_extroverted_stylistic_impressions  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   avg_count_of_interoverted_quantifiers  \\\n",
       "0                                   0.06   \n",
       "1                                   0.14   \n",
       "2                                   0.00   \n",
       "3                                   0.10   \n",
       "4                                   0.00   \n",
       "\n",
       "   avg_count_of_introverted_first_person_singular_pronoun  \\\n",
       "0                                               3.54        \n",
       "1                                               5.58        \n",
       "2                                               5.18        \n",
       "3                                               6.12        \n",
       "4                                               6.10        \n",
       "\n",
       "   avg_count_of_introverted_negations  \n",
       "0                                0.02  \n",
       "1                                0.10  \n",
       "2                                0.04  \n",
       "3                                0.10  \n",
       "4                                0.10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data into a dataset\n",
    "df = pd.read_csv(\"mbit_preprocessed_features.csv\", index_col=0)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c09ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train/test split\n",
    "def create_train_test_split(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42069)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f940880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer created 140798 features.\n"
     ]
    }
   ],
   "source": [
    "# Loads input data from dataset and vectorizes it\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "\n",
    "# Create vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Vectorizer created {} features.\".format(len(vectorizer.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e5957",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36ed68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.6609025         nan 0.65102108        nan        nan\n",
      " 0.66864295 0.65102108]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gridsearch\n",
    "Y = df.iloc[:, 2].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "parameters = {       \n",
    "'penalty': ['l1', 'l2'],\n",
    "'loss': ['hinge', 'squared_hinge'],\n",
    "'dual': [True, False],\n",
    "}\n",
    "\n",
    "estimator = LinearSVC()\n",
    "\n",
    "stratified_3_fold_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search_estimator = GridSearchCV(estimator, parameters, scoring='accuracy', cv=stratified_3_fold_cv)\n",
    "\n",
    "grid_search_estimator.fit(X_train, Y_train)\n",
    "display(grid_search_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a8418",
   "metadata": {},
   "source": [
    "The errors were expected because of some unavailable combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ba365",
   "metadata": {},
   "source": [
    "### Multi-class model (with found parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2ee45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.55      0.31      0.40        55\n",
      "        ENFP       0.72      0.63      0.67       212\n",
      "        ENTJ       0.76      0.43      0.55        74\n",
      "        ENTP       0.62      0.64      0.63       196\n",
      "        ESFJ       1.00      0.36      0.53        11\n",
      "        ESFP       0.00      0.00      0.00        14\n",
      "        ESTJ       0.67      0.18      0.29        11\n",
      "        ESTP       0.69      0.32      0.44        28\n",
      "        INFJ       0.67      0.70      0.69       436\n",
      "        INFP       0.67      0.81      0.73       545\n",
      "        INTJ       0.65      0.62      0.64       365\n",
      "        INTP       0.65      0.76      0.70       378\n",
      "        ISFJ       0.81      0.60      0.69        58\n",
      "        ISFP       0.55      0.44      0.49        73\n",
      "        ISTJ       0.79      0.51      0.62        61\n",
      "        ISTP       0.67      0.57      0.62        86\n",
      "\n",
      "    accuracy                           0.67      2603\n",
      "   macro avg       0.66      0.49      0.54      2603\n",
      "weighted avg       0.67      0.67      0.66      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-class model\n",
    "types = sorted(list(set(df.iloc[:, 0].values)))\n",
    "\n",
    "# Train the model\n",
    "estimator = LinearSVC(penalty='l1', dual=False)\n",
    "estimator.fit(X_train, Y_train)\n",
    "    \n",
    "# Prediction\n",
    "predicted = estimator.predict(X_test)\n",
    "    \n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, predicted, target_names=types, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f67b9c",
   "metadata": {},
   "source": [
    "## Including additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607fd4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaagh</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahh</th>\n",
       "      <th>aaaahhh</th>\n",
       "      <th>aaaaim</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaaanyways</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_exclam_count</th>\n",
       "      <th>avg_fullstop_count</th>\n",
       "      <th>avg_emoji_count</th>\n",
       "      <th>avg_count_of_hello</th>\n",
       "      <th>avg_count_of_hi</th>\n",
       "      <th>avg_count_of_extroverted_bigrams</th>\n",
       "      <th>avg_count_of_extroverted_stylistic_impressions</th>\n",
       "      <th>avg_count_of_interoverted_quantifiers</th>\n",
       "      <th>avg_count_of_introverted_first_person_singular_pronoun</th>\n",
       "      <th>avg_count_of_introverted_negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.276995</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.405321</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.477308</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.339593</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.557121</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.475743</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.699531</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 140809 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaagh  aaaah  aaaahh  aaaahhh  aaaaim  aaaand  \\\n",
       "0     0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "1     0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "2     0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "3     0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "4     0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "...   ...  ...   ...     ...    ...     ...      ...     ...     ...   \n",
       "8670  0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "8671  0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "8672  0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "8673  0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "8674  0.0  0.0   0.0     0.0    0.0     0.0      0.0     0.0     0.0   \n",
       "\n",
       "      aaaanyways  ...  avg_exclam_count  avg_fullstop_count  avg_emoji_count  \\\n",
       "0            0.0  ...              0.00                0.16             0.08   \n",
       "1            0.0  ...              0.00                0.04             0.08   \n",
       "2            0.0  ...              0.00                0.08             0.00   \n",
       "3            0.0  ...              0.00                0.14             0.02   \n",
       "4            0.0  ...              0.00                0.08             0.06   \n",
       "...          ...  ...               ...                 ...              ...   \n",
       "8670         0.0  ...              0.00                0.04             0.08   \n",
       "8671         0.0  ...              0.06                0.26             0.12   \n",
       "8672         0.0  ...              0.00                0.14             0.04   \n",
       "8673         0.0  ...              0.00                0.08             0.00   \n",
       "8674         0.0  ...              0.00                0.06             0.02   \n",
       "\n",
       "      avg_count_of_hello  avg_count_of_hi  avg_count_of_extroverted_bigrams  \\\n",
       "0                    0.0              0.0                              0.14   \n",
       "1                    0.0              0.0                              0.28   \n",
       "2                    0.0              0.0                              0.26   \n",
       "3                    0.0              0.0                              0.20   \n",
       "4                    0.0              0.0                              0.14   \n",
       "...                  ...              ...                               ...   \n",
       "8670                 0.0              0.0                              0.18   \n",
       "8671                 0.0              0.0                              0.12   \n",
       "8672                 0.0              0.0                              0.16   \n",
       "8673                 0.0              0.0                              0.30   \n",
       "8674                 0.0              0.0                              0.28   \n",
       "\n",
       "      avg_count_of_extroverted_stylistic_impressions  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "...                                              ...   \n",
       "8670                                             0.0   \n",
       "8671                                             0.0   \n",
       "8672                                             0.0   \n",
       "8673                                             0.0   \n",
       "8674                                             0.0   \n",
       "\n",
       "      avg_count_of_interoverted_quantifiers  \\\n",
       "0                                      0.06   \n",
       "1                                      0.14   \n",
       "2                                      0.00   \n",
       "3                                      0.10   \n",
       "4                                      0.00   \n",
       "...                                     ...   \n",
       "8670                                   0.12   \n",
       "8671                                   0.06   \n",
       "8672                                   0.02   \n",
       "8673                                   0.16   \n",
       "8674                                   0.10   \n",
       "\n",
       "      avg_count_of_introverted_first_person_singular_pronoun  \\\n",
       "0                                              0.276995        \n",
       "1                                              0.436620        \n",
       "2                                              0.405321        \n",
       "3                                              0.478873        \n",
       "4                                              0.477308        \n",
       "...                                                 ...        \n",
       "8670                                           0.339593        \n",
       "8671                                           0.557121        \n",
       "8672                                           0.475743        \n",
       "8673                                           0.699531        \n",
       "8674                                           0.460094        \n",
       "\n",
       "      avg_count_of_introverted_negations  \n",
       "0                                   0.02  \n",
       "1                                   0.10  \n",
       "2                                   0.04  \n",
       "3                                   0.10  \n",
       "4                                   0.10  \n",
       "...                                  ...  \n",
       "8670                                0.10  \n",
       "8671                                0.12  \n",
       "8672                                0.06  \n",
       "8673                                0.22  \n",
       "8674                                0.18  \n",
       "\n",
       "[8675 rows x 140809 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add features\n",
    "X['avg_word_count'] = df.iloc[:, 8].values\n",
    "X['avg_exclam_count'] = df.iloc[:, 9].values\n",
    "X['avg_fullstop_count'] = df.iloc[:, 10].values\n",
    "X['avg_emoji_count'] = df.iloc[:, 11].values\n",
    "X['avg_count_of_hello'] = df.iloc[:, 12].values\n",
    "X['avg_count_of_hi'] = df.iloc[:, 13].values\n",
    "X['avg_count_of_extroverted_bigrams'] = df.iloc[:, 14].values\n",
    "X['avg_count_of_extroverted_stylistic_impressions'] = df.iloc[:, 15].values\n",
    "X['avg_count_of_interoverted_quantifiers'] = df.iloc[:, 16].values\n",
    "X['avg_count_of_introverted_first_person_singular_pronoun'] = df.iloc[:, 17].values\n",
    "X['avg_count_of_introverted_negations'] = df.iloc[:, 18].values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X[['avg_word_count', 'avg_count_of_introverted_first_person_singular_pronoun']] = scaler.fit_transform(\n",
    "    X[['avg_word_count', 'avg_count_of_introverted_first_person_singular_pronoun']])\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cac1f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "155f80a7",
   "metadata": {},
   "source": [
    "### Multi-class model (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29de3fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.48      0.24      0.32        55\n",
      "        ENFP       0.68      0.61      0.65       212\n",
      "        ENTJ       0.78      0.43      0.56        74\n",
      "        ENTP       0.64      0.62      0.63       196\n",
      "        ESFJ       0.80      0.36      0.50        11\n",
      "        ESFP       0.00      0.00      0.00        14\n",
      "        ESTJ       0.50      0.09      0.15        11\n",
      "        ESTP       0.78      0.25      0.38        28\n",
      "        INFJ       0.65      0.69      0.67       436\n",
      "        INFP       0.63      0.82      0.71       545\n",
      "        INTJ       0.68      0.60      0.63       365\n",
      "        INTP       0.66      0.76      0.70       378\n",
      "        ISFJ       0.82      0.57      0.67        58\n",
      "        ISFP       0.62      0.41      0.50        73\n",
      "        ISTJ       0.73      0.49      0.59        61\n",
      "        ISTP       0.71      0.62      0.66        86\n",
      "\n",
      "    accuracy                           0.66      2603\n",
      "   macro avg       0.63      0.47      0.52      2603\n",
      "weighted avg       0.66      0.66      0.65      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-class model\n",
    "Y = df.iloc[:, 2].values\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "# Train the model\n",
    "estimator = LinearSVC()\n",
    "estimator.fit(X_train, Y_train)\n",
    "    \n",
    "# Prediction\n",
    "predicted = estimator.predict(X_test)\n",
    "    \n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "types = sorted(list(set(df.iloc[:, 0].values)))\n",
    "print(classification_report(Y_test, predicted, target_names=types, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a7031",
   "metadata": {},
   "source": [
    "### Multi-class model (found parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d3da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.55      0.33      0.41        55\n",
      "        ENFP       0.71      0.64      0.67       212\n",
      "        ENTJ       0.73      0.43      0.54        74\n",
      "        ENTP       0.62      0.64      0.63       196\n",
      "        ESFJ       1.00      0.36      0.53        11\n",
      "        ESFP       0.00      0.00      0.00        14\n",
      "        ESTJ       0.67      0.18      0.29        11\n",
      "        ESTP       0.67      0.29      0.40        28\n",
      "        INFJ       0.67      0.69      0.68       436\n",
      "        INFP       0.67      0.82      0.73       545\n",
      "        INTJ       0.66      0.62      0.64       365\n",
      "        INTP       0.64      0.76      0.69       378\n",
      "        ISFJ       0.83      0.59      0.69        58\n",
      "        ISFP       0.55      0.42      0.48        73\n",
      "        ISTJ       0.79      0.49      0.61        61\n",
      "        ISTP       0.67      0.57      0.62        86\n",
      "\n",
      "    accuracy                           0.66      2603\n",
      "   macro avg       0.65      0.49      0.54      2603\n",
      "weighted avg       0.66      0.66      0.66      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model (number of iterations had to be increased because of a ConvergenceWarning)\n",
    "estimator = LinearSVC(penalty='l1', dual=False, max_iter=4000)\n",
    "estimator.fit(X_train, Y_train)\n",
    "    \n",
    "# Prediction\n",
    "predicted = estimator.predict(X_test)\n",
    "    \n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "types = sorted(list(set(df.iloc[:, 0].values)))\n",
    "print(classification_report(Y_test, predicted, target_names=types, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4211e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
