{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e60bac",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab62a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "%pip install -q -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc714f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a879a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>encodedType</th>\n",
       "      <th>preprocessed_posts</th>\n",
       "      <th>extro_intro</th>\n",
       "      <th>intu_obs</th>\n",
       "      <th>feel_think</th>\n",
       "      <th>prosp_judg</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>avg_exclam_count</th>\n",
       "      <th>avg_fullstop_count</th>\n",
       "      <th>avg_emoji_count</th>\n",
       "      <th>avg_count_of_hello</th>\n",
       "      <th>avg_count_of_hi</th>\n",
       "      <th>avg_count_of_extroverted_bigrams</th>\n",
       "      <th>avg_count_of_extroverted_stylistic_impressions</th>\n",
       "      <th>avg_count_of_interoverted_quantifiers</th>\n",
       "      <th>avg_count_of_introverted_first_person_singular_pronoun</th>\n",
       "      <th>avg_count_of_introverted_negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>8</td>\n",
       "      <td>['youtube', 'tumblr', 'enfp', 'intj', 'moment'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>['im', 'finding', 'the', 'lack', 'of', 'post',...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>11</td>\n",
       "      <td>['good', 'one', 'youtube', 'of', 'course', 'i'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>10</td>\n",
       "      <td>['dear', 'intp', 'i', 'enjoyed', 'conversation...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>2</td>\n",
       "      <td>['youre', 'fired', 'thats', 'another', 'silly'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  encodedType  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...            8   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...            3   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           11   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           10   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...            2   \n",
       "\n",
       "                                  preprocessed_posts  extro_intro  intu_obs  \\\n",
       "0  ['youtube', 'tumblr', 'enfp', 'intj', 'moment'...            0         1   \n",
       "1  ['im', 'finding', 'the', 'lack', 'of', 'post',...            1         1   \n",
       "2  ['good', 'one', 'youtube', 'of', 'course', 'i'...            0         1   \n",
       "3  ['dear', 'intp', 'i', 'enjoyed', 'conversation...            0         1   \n",
       "4  ['youre', 'fired', 'thats', 'another', 'silly'...            1         1   \n",
       "\n",
       "   feel_think  prosp_judg  avg_word_count  avg_exclam_count  \\\n",
       "0           1           0           12.10               0.0   \n",
       "1           0           1           24.38               0.0   \n",
       "2           0           1           17.70               0.0   \n",
       "3           0           0           22.26               0.0   \n",
       "4           0           0           20.32               0.0   \n",
       "\n",
       "   avg_fullstop_count  avg_emoji_count  avg_count_of_hello  avg_count_of_hi  \\\n",
       "0                0.16             0.08                 0.0              0.0   \n",
       "1                0.04             0.08                 0.0              0.0   \n",
       "2                0.08             0.00                 0.0              0.0   \n",
       "3                0.14             0.02                 0.0              0.0   \n",
       "4                0.08             0.06                 0.0              0.0   \n",
       "\n",
       "   avg_count_of_extroverted_bigrams  \\\n",
       "0                              0.14   \n",
       "1                              0.28   \n",
       "2                              0.26   \n",
       "3                              0.20   \n",
       "4                              0.14   \n",
       "\n",
       "   avg_count_of_extroverted_stylistic_impressions  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   avg_count_of_interoverted_quantifiers  \\\n",
       "0                                   0.06   \n",
       "1                                   0.14   \n",
       "2                                   0.00   \n",
       "3                                   0.10   \n",
       "4                                   0.00   \n",
       "\n",
       "   avg_count_of_introverted_first_person_singular_pronoun  \\\n",
       "0                                               3.54        \n",
       "1                                               5.58        \n",
       "2                                               5.18        \n",
       "3                                               6.12        \n",
       "4                                               6.10        \n",
       "\n",
       "   avg_count_of_introverted_negations  \n",
       "0                                0.02  \n",
       "1                                0.10  \n",
       "2                                0.04  \n",
       "3                                0.10  \n",
       "4                                0.10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data into a dataset\n",
    "df = pd.read_csv(\"mbit_preprocessed_features.csv\", index_col=0)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1522ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train/test split\n",
    "def create_train_test_split(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42069)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Plot the confusion matrix (copied from Exercise 3)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acac595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads input data from dataset and vectorizes it\n",
    "X = df.iloc[:, 3].values #Preprocessed_posts\n",
    "\n",
    "# Create vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(X)\n",
    "X = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X['avg_word_count'] = df.iloc[:, 8].values\n",
    "X['avg_exclam_count'] = df.iloc[:, 9].values\n",
    "X['avg_fullstop_count'] = df.iloc[:, 10].values\n",
    "X['avg_emoji_count'] = df.iloc[:, 11].values\n",
    "X['avg_count_of_hello'] = df.iloc[:, 12].values\n",
    "X['avg_count_of_hi'] = df.iloc[:, 13].values\n",
    "X['avg_count_of_extroverted_bigrams'] = df.iloc[:, 14].values\n",
    "X['avg_count_of_extroverted_stylistic_impressions'] = df.iloc[:, 15].values\n",
    "X['avg_count_of_interoverted_quantifiers'] = df.iloc[:, 16].values\n",
    "X['avg_count_of_introverted_first_person_singular_pronoun'] = df.iloc[:, 17].values\n",
    "X['avg_count_of_introverted_negations'] = df.iloc[:, 18].values\n",
    "\n",
    "X[['avg_word_count', 'avg_count_of_introverted_first_person_singular_pronoun']] = scaler.fit_transform(\n",
    "    X[['avg_word_count', 'avg_count_of_introverted_first_person_singular_pronoun']])\n",
    "\n",
    "print(\"Vectorizer created {} features.\".format(len(vectorizer.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual types of test data\n",
    "Y_multi = df.iloc[:, 2].values\n",
    "X_train, X_test, Y_train, Y_test_basis = train_test_split(X, Y_multi, test_size=0.3, random_state=42069)\n",
    "types = sorted(list(set(df.iloc[:, 0].values)))\n",
    "\n",
    "def combine_evaluate(intro, sensi, think, judgi):\n",
    "    # Create dataframe\n",
    "    df1 = df[['encodedType', 'extro_intro', 'intu_obs', 'feel_think', 'prosp_judg']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    predict_df = pd.DataFrame(np.transpose([intro, sensi, think, judgi]), \n",
    "                             columns =['extro_intro', 'intu_obs', 'feel_think', 'prosp_judg'])\n",
    "    predict_df = predict_df.merge(df1, how = 'left', on = predict_df.columns.tolist())\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test_basis, predict_df['encodedType'], target_names=types, zero_division=0))\n",
    "\n",
    "    cnf_matrix = confusion_matrix(Y_test_basis, predict_df['encodedType'])\n",
    "    np.set_printoptions(precision=2)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80ceb3",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33a99a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AGANDO\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.84568511        nan 0.84683794        nan        nan\n",
      " 0.84897892 0.84683794]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = df.iloc[:, 4].values # Introverted-Extroverted\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "\n",
    "parameters = {       \n",
    "'penalty': ['l1', 'l2'],\n",
    "'loss': ['hinge', 'squared_hinge'],\n",
    "'dual': [True, False],\n",
    "}\n",
    "\n",
    "estimator = LinearSVC()\n",
    "\n",
    "stratified_3_fold_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search_estimator = GridSearchCV(estimator, parameters, scoring='accuracy', cv=stratified_3_fold_cv)\n",
    "\n",
    "grid_search_estimator.fit(X_train, Y_train)\n",
    "display(grid_search_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a441cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intro = df.iloc[:, 4].values\n",
    "Y_sensi = df.iloc[:, 5].values\n",
    "Y_think = df.iloc[:, 6].values\n",
    "Y_judgi = df.iloc[:, 7].values\n",
    "\n",
    "# Train the model and print the classification report (modified)\n",
    "def train_predict_model(X, Y, types, balancing, found_parameters):\n",
    "    X_train, X_test, Y_train, Y_test = create_train_test_split(X, Y)\n",
    "    \n",
    "    if (balancing):\n",
    "        sampler = RandomOverSampler()\n",
    "        X_train, Y_train = sampler.fit_resample(X_train, Y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    estimator = LinearSVC()\n",
    "    if (found_parameters):\n",
    "        estimator = LinearSVC(penalty='l1', dual=False)\n",
    "    \n",
    "    estimator.fit(X_train, Y_train)\n",
    "    \n",
    "    # Prediction\n",
    "    predicted = estimator.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, predicted, target_names=types, zero_division=0))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(Y_test, predicted)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=types)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12606547",
   "metadata": {},
   "source": [
    "# Binary models (unbalanced, found parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb341ee",
   "metadata": {},
   "source": [
    "### Binary model: Introverted-Extroverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72892d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Introverted-Extroverted\n",
    "predicted_intro = train_predict_model(X, Y_intro, ['Introverted', 'Extroverted'], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07400c8a",
   "metadata": {},
   "source": [
    "### Binary model: Sensing-Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba970ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Sensing-Intuition\n",
    "predicted_sensi = train_predict_model(X, Y_sensi, ['Sensing', 'Intuition'], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21da13",
   "metadata": {},
   "source": [
    "### Binary model: Thinking-Feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Thinking-Feeling\n",
    "predicted_think = train_predict_model(X, Y_think, ['Thinking', 'Feeling'], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66124461",
   "metadata": {},
   "source": [
    "### Binary model: Judging-Perceiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f54abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judging-Perceiving\n",
    "predicted_judgi = train_predict_model(X, Y_judgi, ['Judging', 'Perceiving'], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd24188",
   "metadata": {},
   "source": [
    "### Estimating MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_evaluate(predicted_intro, predicted_sensi, predicted_think, predicted_judgi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25790266",
   "metadata": {},
   "source": [
    "# Binary models (balanced, default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4d1a8",
   "metadata": {},
   "source": [
    "### Binary model: Introverted-Extroverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2529d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Introverted-Extroverted\n",
    "predicted_intro = train_predict_model(X, Y_intro, ['Introverted', 'Extroverted'], True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ca032",
   "metadata": {},
   "source": [
    "### Binary model: Sensing-Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Sensing-Intuition\n",
    "predicted_sensi = train_predict_model(X, Y_sensi, ['Sensing', 'Intuition'], True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20af169",
   "metadata": {},
   "source": [
    "### Binary model: Thinking-Feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Thinking-Feeling\n",
    "predicted_think = train_predict_model(X, Y_think, ['Thinking', 'Feeling'], True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b369a02",
   "metadata": {},
   "source": [
    "### Binary model: Judging-Perceiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judging-Perceiving\n",
    "predicted_judgi = train_predict_model(X, Y_judgi, ['Judging', 'Perceiving'], True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911415c8",
   "metadata": {},
   "source": [
    "### Estimating MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139387d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_evaluate(predicted_intro, predicted_sensi, predicted_think, predicted_judgi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644b787",
   "metadata": {},
   "source": [
    "# Binary models (balanced, found parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8221fd5",
   "metadata": {},
   "source": [
    "### Binary model: Introverted-Extroverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55153ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Introverted-Extroverted\n",
    "predicted_intro = train_predict_model(X, Y_intro, ['Introverted', 'Extroverted'], True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566bd0b",
   "metadata": {},
   "source": [
    "### Binary model: Sensing-Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Sensing-Intuition\n",
    "predicted_sensi = train_predict_model(X, Y_sensi, ['Sensing', 'Intuition'], True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16352172",
   "metadata": {},
   "source": [
    "### Binary model: Thinking-Feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary: Thinking-Feeling\n",
    "predicted_think = train_predict_model(X, Y_think, ['Thinking', 'Feeling'], True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4ecb1",
   "metadata": {},
   "source": [
    "### Binary model: Judging-Perceiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b230696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judging-Perceiving\n",
    "predicted_judgi = train_predict_model(X, Y_judgi, ['Judging', 'Perceiving'], True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082ca5f",
   "metadata": {},
   "source": [
    "### Estimating MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_evaluate(predicted_intro, predicted_sensi, predicted_think, predicted_judgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa74f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
